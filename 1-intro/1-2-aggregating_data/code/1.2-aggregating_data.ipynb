{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadísticas resumidas\n",
    "\n",
    "### Media y mediana\n",
    "\n",
    "Las estadísticas resumidas son exactamente lo que su nombre indica: resumen muchos números en una sola estadística. Por ejemplo, la media, la mediana, el mínimo, el máximo y la desviación estándar son estadísticas resumidas. Calcular estadísticas resumidas te permite obtener una mejor comprensión de tus datos, incluso si hay una gran cantidad de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../../../datasets/walmart.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Explora tu nuevo DataFrame imprimiendo las primeras filas del DataFrame `sales`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imprime información sobre las columnas en `sales`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imprime la media de la columna `weekly_sales`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sales['weekly_sales'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imprime la mediana de la columna `weekly_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imprime el valor máximo de la columna `date`.\n",
    "- Imprime el valor mínimo de la columna `date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales['date'].max())\n",
    "\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resúmenes eficientes**\n",
    "\n",
    "Aunque pandas y NumPy tienen muchas funciones, a veces puedes necesitar una función diferente para resumir tus datos.\n",
    "\n",
    "El método `.agg()` te permite aplicar tus propias funciones personalizadas a un DataFrame, así como aplicar funciones a más de una columna a la vez, haciendo que tus agregaciones sean súper eficientes. Por ejemplo:\n",
    "\n",
    "```python\n",
    "df[‘columna’].agg(función)\n",
    "```\n",
    "\n",
    "En la función personalizada para este ejercicio, \"IQR\" es la abreviatura de rango intercuartílico, que es el percentil 75 menos el percentil 25. Es una alternativa a la desviación estándar que resulta útil si tus datos contienen valores atípicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usa la función personalizada `iqr` definida para ti junto con `.agg()` para imprimir el rango intercuartílico (IQR) de la columna `temperature_c` de `sales`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actualiza la selección de columnas para usar la función personalizada `iqr` con `.agg()` e imprimir el IQR de `temperature_c`, `fuel_price_usd_per_l` y `unemployment`, en ese orden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actualiza las funciones de agregación llamadas por `.agg()`: incluye `iqr` y `np.median` en ese orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, 'median']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Estadísticas acumulativas**\n",
    "\n",
    "Las estadísticas acumulativas también pueden ser útiles para realizar un seguimiento de los resúmenes estadísticos a lo largo del tiempo. En este ejercicio, calcularás la suma acumulativa y el máximo acumulativo de las ventas semanales de un departamento, lo que te permitirá identificar el total de ventas hasta el momento, así como las ventas semanales más altas hasta la fecha.\n",
    "\n",
    "Se ha creado un DataFrame llamado `sales_1_1`, que contiene los datos de ventas del departamento 1 de la tienda 1. `pandas` está cargado como `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1_1 = sales[(sales['department'] == 1) & (sales['store'] == 1)]\n",
    "sales_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordena las filas de `sales_1_1` por la columna `date` en orden ascendente.  \n",
    "- Calcula la suma acumulativa de `weekly_sales` y agrégala como una nueva columna en `sales_1_1` llamada `cum_weekly_sales`.  \n",
    "- Calcula el máximo acumulativo de `weekly_sales` y agrégalo como una columna llamada `cum_max_sales`.  \n",
    "- Imprime las columnas `date`, `weekly_sales`, `cum_weekly_sales` y `cum_max_sales`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1_1 = sales_1_1.sort_values('date')\n",
    "\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conteo**\n",
    "\n",
    "### Eliminación de duplicados\n",
    "\n",
    "Eliminar duplicados es una habilidad esencial para obtener conteos precisos, ya que a menudo no quieres contar la misma cosa varias veces. En este ejercicio, crearás algunos nuevos DataFrames utilizando valores únicos de `sales`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elimina las filas de `sales` con pares duplicados de `store` y `type`, guárdalas como `store_types` e imprime las primeras filas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_types = sales.drop_duplicates(subset=['store', 'type'])\n",
    "print(store_types.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elimina las filas de `sales` con pares duplicados de `store` y `department`, guárdalas como `store_depts` e imprime las primeras filas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store_depts = sales.drop_duplicates(subset=['store', 'department'])\n",
    "print(store_depts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtra las filas que corresponden a semanas festivas utilizando la columna `is_holiday` y elimina las fechas duplicadas, guardando el resultado en `holiday_dates`.  \n",
    "- Selecciona la columna `date` de `holiday_dates` e imprímela.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_dates = sales[sales['is_holiday']].drop_duplicates('date')\n",
    "\n",
    "print(holiday_dates['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conteo de variables categóricas**\n",
    "\n",
    "El conteo es una excelente manera de obtener una visión general de tus datos y detectar curiosidades que de otro modo podrían pasar desapercibidas. En este ejercicio, contarás el número de cada tipo de tienda y el número de cada departamento utilizando los DataFrames que creaste en el ejercicio anterior:\n",
    "\n",
    "```python\n",
    "# Eliminar combinaciones duplicadas de tienda/tipo\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "\n",
    "# Eliminar combinaciones duplicadas de tienda/departamento\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuenta el número de tiendas de cada tipo en `store_types`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuenta la proporción de tiendas de cada tipo en `store_types`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuenta el número de departamentos diferentes en `store_depts`, ordenando los conteos en orden descendente.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuenta la proporción de departamentos diferentes en `store_depts`, ordenando las proporciones en orden descendente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Estadísticas resumidas agrupadas**\n",
    "\n",
    "### ¿Qué porcentaje de las ventas ocurrió en cada tipo de tienda?\n",
    "\n",
    "Aunque `.groupby()` es útil, puedes calcular estadísticas resumidas agrupadas sin usarlo.\n",
    "\n",
    "Walmart distingue tres tipos de tiendas: \"supercentros\", \"tiendas de descuento\" y \"mercados vecinales\", codificados en este conjunto de datos como tipo \"A\", \"B\" y \"C\". En este ejercicio, calcularás las ventas totales realizadas en cada tipo de tienda sin utilizar `.groupby()`. Luego, podrás usar estos valores para determinar qué proporción de las ventas totales de Walmart se realizó en cada tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcula el total de `weekly_sales` en todo el conjunto de datos.  \n",
    "- Filtra las tiendas de tipo `\"A\"` y calcula sus ventas semanales totales.  \n",
    "- Repite el proceso para las tiendas de tipo `\"B\"` y `\"C\"`.  \n",
    "- Combina los resultados de A/B/C en una lista y divídelos por `sales_all` para obtener la proporción de ventas por tipo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cálculos con `.groupby()`**\n",
    "\n",
    "El método `.groupby()` facilita mucho el trabajo. En este ejercicio, realizarás los mismos cálculos que en el ejercicio anterior, pero esta vez utilizando `.groupby()`. Además, realizarás cálculos agrupando los datos por dos variables para analizar si las ventas varían según el tipo de tienda dependiendo de si es una semana festiva o no.\n",
    "\n",
    "- Agrupa `sales` por `\"type\"`, calcula la suma de `\"weekly_sales\"` y guárdala en `sales_by_type`.  \n",
    "- Calcula la proporción de ventas en cada tipo de tienda dividiendo por la suma de `sales_by_type`. Asigna el resultado a `sales_propn_by_type`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "sales_propn_by_type = sales_by_type / sum(sales_by_type)\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agrupa `sales` por `\"type\"` y `\"is_holiday\"`, calcula la suma de `weekly_sales` y guárdala en `sales_by_type_is_holiday`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Múltiples resúmenes agrupados**\n",
    "\n",
    "Anteriormente, viste que el método `.agg()` es útil para calcular múltiples estadísticas en múltiples variables. También funciona con datos agrupados. NumPy, que está importado como `np`, tiene muchas funciones para calcular estadísticas resumidas, incluyendo: `np.min`, `np.max`, `np.mean` y `np.median`.\n",
    "\n",
    "- Importa `numpy` con el alias `np`.  \n",
    "- Obtén el mínimo, máximo, media y mediana de `weekly_sales` para cada tipo de tienda utilizando `.groupby()` y `.agg()`. Guarda esto en `sales_stats`. ¡Asegúrate de usar funciones de `numpy`!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([\"min\", \"max\", \"mean\", \"median\"])\n",
    "\n",
    "print(sales_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtén el mínimo, máximo, media y mediana de `unemployment` y `fuel_price_usd_per_l` para cada tipo de tienda. Guarda esto en `unemp_fuel_stats`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\",\"fuel_price_usd_per_l\"]].agg([\"min\", \"max\", \"mean\", \"median\"])\n",
    "\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tablas dinámicas**\n",
    "\n",
    "### **Pivotando sobre una variable**\n",
    "\n",
    "Las tablas dinámicas son la forma estándar de agregar datos en hojas de cálculo.\n",
    "\n",
    "En pandas, las tablas dinámicas son esencialmente otra forma de realizar cálculos agrupados. Es decir, el método `.pivot_table()` es una alternativa a `.groupby()`.\n",
    "\n",
    "En este ejercicio, realizarás cálculos utilizando `.pivot_table()` para replicar los cálculos que realizaste en la lección anterior con `.groupby()`.\n",
    "\n",
    "\n",
    "1. Obtén la media de `weekly_sales` por `type` usando `.pivot_table()` y guárdala como `mean_sales_by_type`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "mean_sales_by_type = (\n",
    "    sales\n",
    "    .pivot_table(\n",
    "        values=\"weekly_sales\",\n",
    "        index=\"type\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Obtén la media y la mediana (usando funciones de NumPy) de `weekly_sales` por `type` utilizando `.pivot_table()` y guárdala como `mean_med_sales_by_type`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/h3dg3qkd6b9fh7skk0n78c2r0000gn/T/ipykernel_3952/2246794626.py:5: FutureWarning: The provided callable <function mean at 0x11c4967a0> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  .pivot_table(\n",
      "/var/folders/6y/h3dg3qkd6b9fh7skk0n78c2r0000gn/T/ipykernel_3952/2246794626.py:5: FutureWarning: The provided callable <function median at 0x11c5be200> is currently using DataFrameGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  .pivot_table(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_sales_by_type = (\n",
    "    sales\n",
    "    .pivot_table(\n",
    "        values=\"weekly_sales\",\n",
    "        index=\"type\",\n",
    "        aggfunc=[np.mean, np.median]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    }
   ],
   "source": [
    "mean_sales_by_type = (\n",
    "    sales\n",
    "    .pivot_table(\n",
    "        values=\"weekly_sales\",\n",
    "        index=\"type\",\n",
    "        aggfunc=[\"mean\", \"median\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Obtén la media de `weekly_sales` por `type` y `is_holiday` utilizando `.pivot_table()` y guárdala como `mean_sales_by_type_holiday`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday         False      True \n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "mean_sales_by_type_holiday = ( \n",
    "    sales\n",
    "    .pivot_table(\n",
    "        values=\"weekly_sales\",\n",
    "        index=\"type\",\n",
    "        columns=\"is_holiday\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rellenar valores faltantes y sumar valores con tablas dinámicas**\n",
    "\n",
    "El método `.pivot_table()` tiene varios argumentos útiles, incluyendo `fill_value` y `margins`.\n",
    "\n",
    "- `fill_value` reemplaza los valores faltantes con un valor real (*imputación*). La decisión sobre qué valor usar para reemplazar los valores faltantes es un tema amplio que merece un sección entera, pero por ahora la forma más sencilla es sustituir un valor ficticio.  \n",
    "- `margins` es un atajo útil cuando se pivota por dos variables, pero también se quiere calcular totales para cada una de ellas por separado: proporciona los totales de filas y columnas dentro del contenido de la tabla dinámica.  \n",
    "\n",
    "En este ejercicio, practicarás el uso de estos argumentos para mejorar tus habilidades con las tablas dinámicas, lo que te ayudará a procesar datos de manera más eficiente.  \n",
    "\n",
    "\n",
    "- Imprime la media de `weekly_sales` por `department` y `type`, rellenando cualquier valor faltante con `0`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                    A              B\n",
      "department                              \n",
      "1            30961.725379   44050.626667\n",
      "2            67600.158788  112958.526667\n",
      "3            17160.002955   30580.655000\n",
      "4            44285.399091   51219.654167\n",
      "5            34821.011364   63236.875000\n",
      "...                   ...            ...\n",
      "95          123933.787121   77082.102500\n",
      "96           21367.042857    9528.538333\n",
      "97           28471.266970    5828.873333\n",
      "98           12875.423182     217.428333\n",
      "99             379.123659       0.000000\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sales\n",
    "    .pivot_table(\n",
    "        values=\"weekly_sales\",\n",
    "        index=\"department\",\n",
    "        columns=\"type\",\n",
    "        fill_value=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imprime la media de `weekly_sales` por `department` y `type`, rellenando cualquier valor faltante con `0` y sumando todas las filas y columnas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30961.725379</td>\n",
       "      <td>44050.626667</td>\n",
       "      <td>32052.467153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67600.158788</td>\n",
       "      <td>112958.526667</td>\n",
       "      <td>71380.022778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17160.002955</td>\n",
       "      <td>30580.655000</td>\n",
       "      <td>18278.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44285.399091</td>\n",
       "      <td>51219.654167</td>\n",
       "      <td>44863.253681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34821.011364</td>\n",
       "      <td>63236.875000</td>\n",
       "      <td>37189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>21367.042857</td>\n",
       "      <td>9528.538333</td>\n",
       "      <td>20337.607681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>28471.266970</td>\n",
       "      <td>5828.873333</td>\n",
       "      <td>26584.400833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>12875.423182</td>\n",
       "      <td>217.428333</td>\n",
       "      <td>11820.590278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>379.123659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>379.123659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>23674.667242</td>\n",
       "      <td>25696.678370</td>\n",
       "      <td>23843.950149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "type                   A              B           All\n",
       "department                                           \n",
       "1           30961.725379   44050.626667  32052.467153\n",
       "2           67600.158788  112958.526667  71380.022778\n",
       "3           17160.002955   30580.655000  18278.390625\n",
       "4           44285.399091   51219.654167  44863.253681\n",
       "5           34821.011364   63236.875000  37189.000000\n",
       "...                  ...            ...           ...\n",
       "96          21367.042857    9528.538333  20337.607681\n",
       "97          28471.266970    5828.873333  26584.400833\n",
       "98          12875.423182     217.428333  11820.590278\n",
       "99            379.123659       0.000000    379.123659\n",
       "All         23674.667242   25696.678370  23843.950149\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    sales\n",
    "    .pivot_table(\n",
    "        values=\"weekly_sales\",\n",
    "        index=\"department\",\n",
    "        columns=\"type\",\n",
    "        fill_value=0,\n",
    "        margins=True\n",
    "    )\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcd-projectsI2025a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
